index 91861b8..9a306b5 100644
--- a/nvidia-uvm/uvm8_page_tree_test.c
+++ b/nvidia-uvm/uvm8_page_tree_test.c
@@ -55,7 +55,7 @@ static void fake_ce_memset_8(uvm_push_t *push, uvm_gpu_address_t dst, NvU64 valu
         *(NvU64 *)phys_to_virt(dst.address + i) = value;
 }
 
-void *cpu_addr_from_fake(uvm_gpu_address_t fake_gpu_addr)
+static void *cpu_addr_from_fake(uvm_gpu_address_t fake_gpu_addr)
 {
     if (fake_gpu_addr.is_virtual)
         return (void*)fake_gpu_addr.address;
@@ -69,16 +69,16 @@ static void fake_ce_memcopy(uvm_push_t *push, uvm_gpu_address_t dst, uvm_gpu_add
     memcpy(cpu_addr_from_fake(dst), cpu_addr_from_fake(src), size);
 }
 
-void fake_wait_for_idle(uvm_push_t *push)
+static void fake_wait_for_idle(uvm_push_t *push)
 {
 }
 
-void fake_noop(uvm_push_t *push, NvU32 size)
+static void fake_noop(uvm_push_t *push, NvU32 size)
 {
     push->next += size / 4;
 }
 
-void fake_membar(uvm_push_t *push)
+static void fake_membar(uvm_push_t *push)
 {
 }
 
@@ -304,7 +304,7 @@ static NV_STATUS test_page_tree_get_entry(uvm_page_tree_t *tree, NvU32 page_size
     return uvm_page_tree_get_entry(tree, page_size, start, UVM_PMM_ALLOC_FLAGS_NONE, single);
 }
 
-NV_STATUS test_page_tree_alloc_table(uvm_page_tree_t *tree, NvU32 page_size,
+static NV_STATUS test_page_tree_alloc_table(uvm_page_tree_t *tree, NvU32 page_size,
         uvm_page_table_range_t *single, uvm_page_table_range_t *children)
 {
     return uvm_page_tree_alloc_table(tree, page_size, UVM_PMM_ALLOC_FLAGS_NONE, single, children);
